{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##hash function"
      ],
      "metadata": {
        "id": "PzcfK9Gqty9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import itertools\n",
        "start = time.time()\n",
        "\n",
        "def hash(element1,element2,num_trans):\n",
        "  result = (element1 + element2) % num_trans\n",
        "  return result"
      ],
      "metadata": {
        "id": "3FBVuzYAtyPl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data && generate C1 and pairs for bucket"
      ],
      "metadata": {
        "id": "D2cLwkQlz54F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w6AM2UKXzJis"
      },
      "outputs": [],
      "source": [
        "candidates = {}\n",
        "buckets = {}\n",
        "num_trans = 0\n",
        "with open('retail.txt', 'r') as file:\n",
        "    for line in file:\n",
        "      num_trans += 1\n",
        "\n",
        "def read_data(num_trans,candidates,buckets):\n",
        "  all_data = []\n",
        "  with open('retail.txt', 'r') as file:\n",
        "    for line in file:\n",
        "      line_list = [int(x) for x in line.strip().split()]\n",
        "      all_data.append(line_list)\n",
        "      for item in line_list:\n",
        "        if item in candidates.keys():\n",
        "          candidates.update({item:(candidates[item]+1)})\n",
        "        else:\n",
        "          candidates.update({item:1})\n",
        "      pairs = list(itertools.combinations(line_list, 2))\n",
        "      for pair in pairs:\n",
        "        index = hash(pair[0], pair[1],num_trans)\n",
        "        if index in buckets.keys():\n",
        "          buckets.update({index:(buckets[index]+1)})\n",
        "        else:\n",
        "          buckets.update({index:1})\n",
        "  return all_data,candidates,buckets\n",
        "#netflix.data retail.txt\n",
        "\n",
        "# get transactions,c1,buckets\n",
        "all_data,c1,buckets = read_data(num_trans,candidates,buckets)\n",
        "min_support = 0.02\n",
        "#0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Bitmap\n"
      ],
      "metadata": {
        "id": "KSurVJ3d_UYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_Bitmap(hashtable,num_trans,min_support):\n",
        "  bitmap = [0]*num_trans\n",
        "  for bucket,bucket_count in hashtable.items():\n",
        "    if bucket_count/num_trans >= min_support:\n",
        "      bitmap[bucket] = 1\n",
        "  return bitmap"
      ],
      "metadata": {
        "id": "MeaO6owz_agJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate L1"
      ],
      "metadata": {
        "id": "SKCQRNUEvKCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_L(candidates,num_trans,min_support):\n",
        "  L = []\n",
        "  for key,value in candidates.items():\n",
        "    if value/num_trans >= min_support:\n",
        "      L.append(key)\n",
        "  return L\n",
        "\n",
        "L1 = get_L(c1,num_trans,min_support)"
      ],
      "metadata": {
        "id": "Vo6a60n-vXSy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prune Dataset"
      ],
      "metadata": {
        "id": "TZVBF6OL2PrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_dataset(candidates,transactions):\n",
        "  pruned_dataset = []\n",
        "  for basket in transactions:\n",
        "    for item in basket:\n",
        "      if item in candidates:\n",
        "        pruned_dataset.append(basket)\n",
        "        break\n",
        "  return pruned_dataset\n",
        "\n",
        "pruned_dataset = prune_dataset(L1,all_data)"
      ],
      "metadata": {
        "id": "VH-AfTy42TKk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Count initially_pruned C2"
      ],
      "metadata": {
        "id": "wH3KVItd22RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_C2(candidates,dataset):\n",
        "  for basket in dataset:\n",
        "    for key in candidates.keys():\n",
        "      if set(key).issubset(set(basket)):\n",
        "        candidates.update({key:candidates[key]+1})\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "hC4ypDox24Tr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate C2 && bitmap"
      ],
      "metadata": {
        "id": "IRA-gsd5xwFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C2 = list(itertools.combinations(L1, 2))\n",
        "\n",
        "bitmap = generate_Bitmap(buckets,num_trans,min_support)\n",
        "\n",
        "# count = 0\n",
        "# for pair in C2:\n",
        "#   if hash(pair[0],pair[1]) in buckets.keys():\n",
        "#     count += 1\n"
      ],
      "metadata": {
        "id": "bMwjCd0Wxygu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate L2"
      ],
      "metadata": {
        "id": "aPdfeXSjzJJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_L2(C2,bitmap,num_trans,pruned_dataset,min_support):\n",
        "  for pair in C2:\n",
        "    index = hash(pair[0], pair[1],num_trans)\n",
        "    if bitmap[index] != 1:\n",
        "      C2.remove(pair)\n",
        "      \n",
        "  if len(C2) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    initial_value = [0]*len(C2)\n",
        "    C2_initial = dict(zip(C2, initial_value))\n",
        "    C2_initial = get_C2(C2_initial,pruned_dataset)\n",
        "    L2 = get_L(C2_initial,num_trans,min_support)\n",
        "    return L2\n",
        "\n",
        "L2 = get_L2(C2,bitmap,num_trans,pruned_dataset,min_support)\n",
        "print(len(L2))\n",
        "for pair in L2:\n",
        "  print(pair)\n",
        "print(\"--- seconds---\" , (time.time() - start))"
      ],
      "metadata": {
        "id": "-b9qXnPIzI-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}