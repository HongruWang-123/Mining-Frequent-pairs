{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##hash function"
      ],
      "metadata": {
        "id": "PzcfK9Gqty9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "start = time.time()\n",
        "\n",
        "def hash(element1,element2,num_trans):\n",
        "  result = (element1 + element2) % num_trans\n",
        "  return result"
      ],
      "metadata": {
        "id": "3FBVuzYAtyPl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data && split dataset into 4 subsets && generate C1 and pairs for each subset"
      ],
      "metadata": {
        "id": "D2cLwkQlz54F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w6AM2UKXzJis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e866b5-60e5-4e66-9ba4-611730abe04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88162\n"
          ]
        }
      ],
      "source": [
        "candidates_1 = {}\n",
        "candidates_2 = {}\n",
        "candidates_3 = {}\n",
        "candidates_4 = {}\n",
        "\n",
        "buckets_1 = {}\n",
        "buckets_2 = {}\n",
        "buckets_3 = {}\n",
        "buckets_4 = {}\n",
        "\n",
        "\n",
        "num_trans = 0\n",
        "all_data = []\n",
        "#read all basket from file\n",
        "with open('retail.txt', 'r') as file:\n",
        "  for line in file:\n",
        "    num_trans += 1\n",
        "    line_list = [int(x) for x in line.strip().split()]\n",
        "    all_data.append(line_list)\n",
        "print(len(all_data))\n",
        "\n",
        "#slice dataset into 4 parts\n",
        "data_partition_1 = all_data[0:int(num_trans/4)]\n",
        "num_trans_1 = len(data_partition_1)\n",
        "\n",
        "data_partition_2 = all_data[int(num_trans/4):int(num_trans*(2/4))]\n",
        "num_trans_2 = len(data_partition_2)\n",
        "\n",
        "data_partition_3 = all_data[int(num_trans*2/4):int(num_trans*3/4)]\n",
        "num_trans_3 = len(data_partition_3)\n",
        "\n",
        "data_partition_4 = all_data[int(num_trans*3/4):num_trans]\n",
        "num_trans_4 = len(data_partition_4)\n",
        "\n",
        "def count_data(data_partition,candidates,buckets):\n",
        "    for line in data_partition:\n",
        "      for item in line:\n",
        "        if item in candidates.keys():\n",
        "          candidates.update({item:(candidates[item]+1)})\n",
        "        else:\n",
        "          candidates.update({item:1})\n",
        "      pairs = list(itertools.combinations(line_list, 2))\n",
        "      for pair in pairs:\n",
        "        index = hash(pair[0], pair[1],num_trans)\n",
        "        if index in buckets.keys():\n",
        "          buckets.update({index:(buckets[index]+1)})\n",
        "        else:\n",
        "          buckets.update({index:1})\n",
        "    return candidates,buckets\n",
        "#netflix.data retail.txt\n",
        "\n",
        "# get transactions,c1,buckets\n",
        "c1_1,buckets_1 = count_data(data_partition_1,candidates_1,buckets_1)\n",
        "c1_2,buckets_2 = count_data(data_partition_2,candidates_2,buckets_2)\n",
        "c1_3,buckets_3 = count_data(data_partition_3,candidates_3,buckets_3)\n",
        "c1_4,buckets_4 = count_data(data_partition_2,candidates_2,buckets_2)\n",
        "min_support = 0.02\n",
        "#0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Bitmap\n"
      ],
      "metadata": {
        "id": "KSurVJ3d_UYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_Bitmap(hashtable,num_trans,min_support):\n",
        "  bitmap = [0]*num_trans\n",
        "  for bucket,bucket_count in hashtable.items():\n",
        "    if bucket_count/num_trans >= min_support:\n",
        "      bitmap[bucket] = 1\n",
        "  return bitmap"
      ],
      "metadata": {
        "id": "MeaO6owz_agJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate L1"
      ],
      "metadata": {
        "id": "SKCQRNUEvKCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_L(candidates,num_trans,min_support):\n",
        "  L = []\n",
        "  for key,value in candidates.items():\n",
        "    if value/num_trans >= min_support:\n",
        "      L.append(key)\n",
        "  return L\n",
        "\n",
        "L1_1 = get_L(c1_1,num_trans_1,min_support)\n",
        "L1_2 = get_L(c1_2,num_trans_2,min_support)\n",
        "L1_3 = get_L(c1_3,num_trans_3,min_support)\n",
        "L1_4 = get_L(c1_4,num_trans_4,min_support)"
      ],
      "metadata": {
        "id": "Vo6a60n-vXSy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prune Dataset"
      ],
      "metadata": {
        "id": "TZVBF6OL2PrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_dataset(candidates,transactions):\n",
        "  pruned_dataset = []\n",
        "  for basket in transactions:\n",
        "    for item in basket:\n",
        "      if item in candidates:\n",
        "        pruned_dataset.append(basket)\n",
        "        break\n",
        "  return pruned_dataset\n",
        "\n",
        "pruned_dataset_1 = prune_dataset(L1_1,data_partition_1)\n",
        "pruned_dataset_2 = prune_dataset(L1_2,data_partition_2)\n",
        "pruned_dataset_3 = prune_dataset(L1_3,data_partition_3)\n",
        "pruned_dataset_4 = prune_dataset(L1_4,data_partition_4)"
      ],
      "metadata": {
        "id": "VH-AfTy42TKk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Count initially_pruned C2"
      ],
      "metadata": {
        "id": "wH3KVItd22RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_C2(candidates,dataset):\n",
        "  for basket in dataset:\n",
        "    for key in candidates.keys():\n",
        "      if set(key).issubset(set(basket)):\n",
        "        candidates.update({key:candidates[key]+1})\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "hC4ypDox24Tr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate C2 && bitmap"
      ],
      "metadata": {
        "id": "IRA-gsd5xwFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C2_1 = list(itertools.combinations(L1_1, 2))\n",
        "C2_2 = list(itertools.combinations(L1_2, 2))\n",
        "C2_3 = list(itertools.combinations(L1_3, 2))\n",
        "C2_4 = list(itertools.combinations(L1_4, 2))\n",
        "\n",
        "bitmap_1 = generate_Bitmap(buckets_1,num_trans_1,min_support)\n",
        "bitmap_2 = generate_Bitmap(buckets_2,num_trans_2,min_support)\n",
        "bitmap_3 = generate_Bitmap(buckets_3,num_trans_3,min_support)\n",
        "bitmap_4 = generate_Bitmap(buckets_4,num_trans_4,min_support)\n",
        "\n",
        "# print(bitmap)\n",
        "# count = 0\n",
        "# for pair in C2:\n",
        "#   if hash(pair[0],pair[1]) in buckets.keys():\n",
        "#     count += 1\n"
      ],
      "metadata": {
        "id": "bMwjCd0Wxygu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate L2"
      ],
      "metadata": {
        "id": "aPdfeXSjzJJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import And\n",
        "def get_L2(C2,bitmap,num_trans,pruned_dataset,min_support):\n",
        "  for pair in C2:\n",
        "    index = hash(pair[0], pair[1],num_trans)\n",
        "    if bitmap[index] != 1:\n",
        "      C2.remove(pair)\n",
        "\n",
        "  if len(C2) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    initial_value = [0]*len(C2)\n",
        "    C2_initial = dict(zip(C2, initial_value))\n",
        "    C2_initial = get_C2(C2_initial,pruned_dataset)\n",
        "    L2 = get_L(C2_initial,num_trans,min_support)\n",
        "    return L2\n",
        "\n",
        "L2_1 = get_L2(C2_1,bitmap_1,num_trans_1,pruned_dataset_1,min_support)\n",
        "L2_2 = get_L2(C2_2,bitmap_2,num_trans_2,pruned_dataset_2,min_support)\n",
        "L2_3 = get_L2(C2_3,bitmap_3,num_trans_3,pruned_dataset_3,min_support)\n",
        "L2_4 = get_L2(C2_4,bitmap_4,num_trans_4,pruned_dataset_4,min_support)\n",
        "\n",
        "L2_union = set(L2_1).union(set(L2_2)).union(set(L2_3)).union(set(L2_4))\n",
        "L2_list = list(L2_union)\n",
        "L2_list_2 = []\n",
        "\n",
        "\n",
        "for i in range(len(L2_list)):\n",
        "  flag = False\n",
        "  for j in range(i+1,len(L2_list)):\n",
        "    if L2_list[i][0] == L2_list[j][1] and L2_list[i][1] == L2_list[j][0]:\n",
        "      flag = True\n",
        "  if flag == False:\n",
        "    L2_list_2.append(L2_list[i])\n",
        "\n",
        "def verify_L2(L2_union,num_trans,min_support):\n",
        "   initial_value = [0]*len(L2_union)\n",
        "   C2_union = dict(zip(L2_union, initial_value))\n",
        "   C2_union = get_C2(C2_union,all_data)\n",
        "   return get_L(C2_union,num_trans,min_support)\n",
        "\n",
        "\n",
        "L2 = verify_L2(L2_list_2,num_trans,min_support)\n",
        "print(len(L2))\n",
        "print(L2)\n",
        "print(\"--- seconds---\" , (time.time() - start))"
      ],
      "metadata": {
        "id": "-b9qXnPIzI-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}